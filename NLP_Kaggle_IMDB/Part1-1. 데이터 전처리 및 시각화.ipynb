{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP는? NLP(자연어처리)는 텍스트 문제에 접근하기 위한 기술집합이다. 이 튜토리얼에서는 IMDB 영화 리뷰를 로딩하고 정제하고 간단한 BOW(Bag of Words) 모델을 적용하여 리뷰가 추천인지 아닌지에 대한 정확도를 예측한다.\n",
    "\n",
    "https://github.com/corazzon/KaggleStruggle/blob/master/word2vec-nlp-tutorial/tutorial-part-1.ipynb\n",
    "\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "- labeledTrainData.tsv\n",
    "- sampleSubmission.csv\n",
    "- testData.tsv\n",
    "- unlabeledTrainData.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:27.623617Z",
     "start_time": "2020-05-14T07:55:26.448674Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며 \n",
    "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
    "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
    "\"\"\"\n",
    "# QUOTE_MINIMAL (0), QUOTE_ALL (1), \n",
    "# QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "\n",
    "# 레이블인 sentiment 가 있는 학습 데이터\n",
    "train = pd.read_csv('data/word2vec-nlp-tutorial/labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
    "# 레이블이 없는 테스트 데이터\n",
    "test = pd.read_csv('data/word2vec-nlp-tutorial/testData.tsv', delimiter='\\t', quoting=3)\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:27.685018Z",
     "start_time": "2020-05-14T07:55:27.665086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'sentiment' 'review']\n",
      "(25000, 3)\n",
      "1    12500\n",
      "0    12500\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## id, sentiment, review\n",
    "## labeling : sentiment (0 or 1)\n",
    "### 1 : positive\n",
    "print(train.columns.values)\n",
    "print(train.shape)\n",
    "print(train['sentiment'].value_counts())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:27.727578Z",
     "start_time": "2020-05-14T07:55:27.718546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'review']\n",
      "(25000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## id, review\n",
    "## No labeling\n",
    "print(test.columns.values)\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정제 \n",
    "\n",
    "***Data Cleaning and Text Preprocessing***\n",
    "\n",
    "기계가 텍스트를 이해할 수 있도록 텍스트를 정제해 준다.\n",
    "\n",
    "신호와 소음을 구분한다. 아웃라이어데이터로 인한 오버피팅을 방지한다.\n",
    "\n",
    "1. BeautifulSoup(뷰티풀숩)을 통해 HTML 태그를 제거\n",
    "2. 정규표현식으로 알파벳 이외의 문자를 공백으로 치환\n",
    "3. NLTK 데이터를 사용해 불용어(Stopword)를 제거\n",
    "4. 어간추출(스테밍 Stemming)과 음소표기법(Lemmatizing)의 개념을 이해하고 SnowballStemmer를 통해 어간을 추출\n",
    "\n",
    "***\n",
    "\n",
    "***한국어 텍스트 데이터 전처리***\n",
    "\n",
    "텍스트 데이터 전처리 이해하기(출처 : [트위터 한국어 형태소 분석기](https://github.com/twitter/twitter-korean-text))\n",
    "\n",
    "konlpy --> twitter_korean_text : normalization, tokenization, stemming, phrase extraction 지원\n",
    "\n",
    "**정규화 normalization (입니닼ㅋㅋ -> 입니다 ㅋㅋ, 샤릉해 -> 사랑해)**\n",
    "\n",
    "- 한국어를 처리하는 예시입니닼ㅋㅋㅋㅋㅋ \n",
    "    - 한국어를 처리하는 예시입니다 ㅋㅋ\n",
    "\n",
    "**토큰화 tokenization**\n",
    "\n",
    "- 한국어를 처리하는 예시입니다ㅋㅋ \n",
    "    - 한국어Noun,를Josa, 처리Noun, 하는Verb, 예시Noun, 입Adjective, 니다Eomi ㅋㅋKoreanParticle\n",
    "    \n",
    "**어근화 stemming (입니다 -> 이다)**\n",
    "- 어간 : 단어의 의미를 담고 있는 단어의 핵심 부분\n",
    "- 한국어를 처리하는 예시입니다 ㅋㅋ  \n",
    "    - 한국어Noun, 를Josa, 처리Noun, 하다Verb, 예시Noun, 이다Adjective, ㅋㅋKoreanParticle\n",
    "\n",
    "**어구 추출 phrase extraction**\n",
    "\n",
    "- 한국어를 처리하는 예시입니다 ㅋㅋ \n",
    "    - 한국어, 처리, 예시, 처리하는 예시\n",
    "    \n",
    "***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:27.771759Z",
     "start_time": "2020-05-14T07:55:27.764836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle mess'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][0][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:28.799187Z",
     "start_time": "2020-05-14T07:55:27.813651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: beautifulsoup4\r\n",
      "Version: 4.9.0\r\n",
      "Summary: Screen-scraping library\r\n",
      "Home-page: http://www.crummy.com/software/BeautifulSoup/bs4/\r\n",
      "Author: Leonard Richardson\r\n",
      "Author-email: leonardr@segfault.org\r\n",
      "License: MIT\r\n",
      "Location: /Users/imsoyoung/opt/anaconda3/envs/nlp/lib/python3.6/site-packages\r\n",
      "Requires: soupsieve\r\n",
      "Required-by: bs4\r\n"
     ]
    }
   ],
   "source": [
    "# conda install beautifulsoup4\n",
    "# conda install scrapy\n",
    "# conda install html5lib\n",
    "# python3 -m pip install lxml\n",
    "\n",
    "!pip show BeautifulSoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautifulsoup 을 이용해 html 태그 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:30.536746Z",
     "start_time": "2020-05-14T07:55:28.834841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "example1 = BeautifulSoup(train['review'][0], \"html.parser\")\n",
    "print(train['review'][0][:700])\n",
    "\n",
    "example1.get_text()[:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규표현식으로 알파벳 이외의 문자를 공백으로 치환\n",
    "- 대문자 -->소문자로 변환 (같은 문자라도 소문자,대문자에 따라 다른 문자로 인식할 수 있기 때문에)\n",
    "\n",
    "[^a-zA-Z] : a-z, A-Z 가 아니면(^)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:30.585350Z",
     "start_time": "2020-05-14T07:55:30.578337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식으로 특수문자 제거\n",
    "import re\n",
    "\n",
    "letters_only = re.sub('[^a-zA-Z]', ' ', example1.get_text())\n",
    "letters_only[:700]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:30.645544Z",
     "start_time": "2020-05-14T07:55:30.635760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'all',\n",
       " 'this',\n",
       " 'stuff',\n",
       " 'going',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'with']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소문자로 변환\n",
    "lower_case = letters_only.lower()\n",
    "\n",
    "# 문자 나누기 => 토큰화\n",
    "words = lower_case.split()\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불용어 제거\n",
    "\n",
    "일반적으로 코퍼스에서 자주 나타나는 단어는 학습 모델로서 학습이나 예측 프로세스에 실제로 기여하지 않아 다른 텍스트와 구별하지 못한다. 예를들어 조사, 접미사, i, me, my, it, this, that, is, are 등 과 같은 단어는 빈번하게 등장하지만 실제 의미를 찾는데 큰 기여를 하지 않는다. Stopwords는 \"to\"또는 \"the\"와 같은 용어를 포함하므로 사전 처리 단계에서 제거하는 것이 좋다. NLTK에는 153 개의 영어 불용어가 미리 정의되어 있다. 17개의 언어에 대해 정의되어 있으며 한국어는 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:31.075480Z",
     "start_time": "2020-05-14T07:55:30.699718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:31.180755Z",
     "start_time": "2020-05-14T07:55:31.103621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords 를 제거한 토큰\n",
    "words = [w for w in words if not w in stopwords.words('english')]\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming (어간 추출, 형태소 분석)\n",
    "\n",
    "[어간추출이란?](https://ko.wikipedia.org/wiki/%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C)\n",
    "(어간 : 문법에서 어형 변화의 기초가 되는 부분)\n",
    "\n",
    "- 어간 추출(語幹 抽出, 영어: stemming)은 어형이 변형된 단어로부터 접사 등을 제거하고 그 단어의 어간을 분리해 내는 것\n",
    "- \"message\", \"messages\", \"messaging\" 과 같이 복수형, 진행형 등의 문자를 같은 의미의 단어로 다룰 수 있도록 도와준다.\n",
    "- stemming(형태소 분석): 여기에서는 NLTK에서 제공하는 형태소 분석기를 사용한다. **포터 형태소 분석기**는 보수적이고 **랭커스터 형태소 분석기**는 좀 더 적극적이다. 형태소 분석 규칙의 적극성 때문에 랭커스터 형태소 분석기는 더 많은 동음이의어 형태소를 생산한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:31.215196Z",
     "start_time": "2020-05-14T07:55:31.211091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum\n",
      "The stemmed form of running is: run\n",
      "The stemmed form of runs is: run\n",
      "The stemmed form of run is: run\n"
     ]
    }
   ],
   "source": [
    "# 포터 스태머의 사용 예\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "print(stemmer.stem('maximum'))\n",
    "print(\"The stemmed form of running is: {}\".format(stemmer.stem(\"running\")))\n",
    "print(\"The stemmed form of runs is: {}\".format(stemmer.stem(\"runs\")))\n",
    "print(\"The stemmed form of run is: {}\".format(stemmer.stem(\"run\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:31.261865Z",
     "start_time": "2020-05-14T07:55:31.254250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxim\n",
      "The stemmed form of running is: run\n",
      "The stemmed form of runs is: run\n",
      "The stemmed form of run is: run\n"
     ]
    }
   ],
   "source": [
    "# 랭커스터 스태머의 사용 예\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "print(lancaster_stemmer.stem('maximum'))\n",
    "print(\"The stemmed form of running is: {}\".format(lancaster_stemmer.stem(\"running\")))\n",
    "print(\"The stemmed form of runs is: {}\".format(lancaster_stemmer.stem(\"runs\")))\n",
    "print(\"The stemmed form of run is: {}\".format(lancaster_stemmer.stem(\"run\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:31.309895Z",
     "start_time": "2020-05-14T07:55:31.304567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처리 전\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:31.364273Z",
     "start_time": "2020-05-14T07:55:31.355310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'go',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'start',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'watch',\n",
       " 'odd',\n",
       " 'documentari']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "words = [stemmer.stem(w) for w in words]\n",
    "\n",
    "# 처리 후\n",
    "## going ==> go\n",
    "## started ==> start\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization (음소표기법, 표제어 추출)\n",
    "\n",
    "언어학에서 음소 표기법 (또는 lemmatization)은 단어의 보조 정리 또는 사전 형식에 의해 식별되는 단일 항목으로 분석 될 수 있도록 굴절 된 형태의 단어를 그룹화하는 과정이다(다른 형태를 갖더라도 그 뿌리 단어를 찾아가 단어의 개수를 줄일 수 있는지 판단). 예를 들어 동음이의어가 문맥에 따라 다른 의미를 갖는데\n",
    "\n",
    "1) *배*가 맛있다.    \n",
    "2) *배*를 타는 것이 재미있다.    \n",
    "3) 평소보다 두 *배*로 많이 먹어서 *배*가 아프다   \n",
    "\n",
    "위에 있는 3개의 문장에 있는 \"배\"는 모두 다른 의미를 갖는다.\n",
    "레마타이제이션은 이때 **앞뒤 문맥을 보고 단어의 의미를 식별**하는 것이다. 영어에서 meet는 meeting으로 쓰였을 때 회의를 뜻하지만 meet 일 때는 만나다는 뜻을 갖는데 그 단어가 명사로 쓰였는지 동사로 쓰였는지에 따라 적합한 의미를 갖도록 추출하는 것이다.\n",
    "\n",
    "참고 : [어간추출(Stemming)과 표제어 추출(Lemmatization)](https://wikidocs.net/21707)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:33.475235Z",
     "start_time": "2020-05-14T07:55:31.896532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly\n",
      "fly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'go',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'start',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'watch',\n",
       " 'odd',\n",
       " 'documentari']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize('fly'))\n",
    "print(wordnet_lemmatizer.lemmatize('flies'))\n",
    "\n",
    "words = [wordnet_lemmatizer.lemmatize(w) for w in words]\n",
    "# 처리 후 단어\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자열 처리 자동화\n",
    "\n",
    "- 데이터 정제 함수화\n",
    "    - HTML 태그 제거\n",
    "    - 불용어 제거\n",
    "    - Stemming\n",
    "    - Lemmatization\n",
    "    \n",
    "- 대용량 데이터 빠르게 처리 --> multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:33.777529Z",
     "start_time": "2020-05-14T07:55:33.772564Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # 1. HTML 제거\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    # 2. 영문자가 아닌 문자는 공백으로 변환\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    # 3. 소문자 변환\n",
    "    words = letters_only.lower().split()\n",
    "    # 4. 파이썬에서는 리스트보다 세트로 찾는게 훨씬 빠르다.\n",
    "    # stopwords 를 세트로 변환한다.\n",
    "    stops = set(stopwords.words('english'))\n",
    "    # 5. Stopwords 불용어 제거\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. 어간추출\n",
    "    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n",
    "    # 7. 공백으로 구분된 문자열로 결합하여 결과를 반환\n",
    "    return( ' '.join(stemming_words) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:34.369942Z",
     "start_time": "2020-05-14T07:55:34.366055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰수 확인\n",
    "num_reviews = train['review'].size\n",
    "num_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:35.958457Z",
     "start_time": "2020-05-14T07:55:35.953873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n코드는 한 줄로 간결해 졌지만 여전히 오래 걸림\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "clean_train_reviews = []\n",
    "\"\"\"\n",
    "# for i in range(0, num_reviews):\n",
    "#     clean_train_reviews.append( review_to_words(train['review'][i]))\n",
    "\"\"\"\n",
    "하지만 위 코드는 어느 정도 실행이 되고 있는지 알 수가 없어서\n",
    "5000개 단위로 상태를 찍도록 개선했다.\n",
    "\"\"\"\n",
    "# clean_train_reviews = []\n",
    "# for i in range(0, num_reviews):\n",
    "#     if (i + 1)%5000 == 0:\n",
    "#         print('Review {} of {} '.format(i+1, num_reviews))\n",
    "#     clean_train_reviews.append(review_to_words(train['review'][i]))\n",
    "    \n",
    "\"\"\"\n",
    "그리고 코드를 좀 더 간결하게 하기 위해 for loop를 사용하는 \n",
    "대신 apply를 사용하도록 개선\n",
    "\"\"\"    \n",
    "# %time train['review_clean'] = train['review'].apply(review_to_words)\n",
    "\"\"\"\n",
    "코드는 한 줄로 간결해 졌지만 여전히 오래 걸림\n",
    "\"\"\"\n",
    "# CPU times: user 1min 15s, sys: 2.3 s, total: 1min 18s\n",
    "# Wall time: 1min 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:37.407280Z",
     "start_time": "2020-05-14T07:55:37.402142Z"
    }
   },
   "outputs": [],
   "source": [
    "# 참고 : https://gist.github.com/yong27/7869662\n",
    "# http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    # 키워드 항목 중 workers 파라메터를 꺼냄\n",
    "    workers = kwargs.pop('workers')\n",
    "    # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
    "    pool = Pool(processes=workers)\n",
    "    # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    # 작업 결과를 합쳐서 반환\n",
    "    return pd.concat(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:55:54.930758Z",
     "start_time": "2020-05-14T07:55:38.212803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 92.8 ms, sys: 99.5 ms, total: 192 ms\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%time clean_train_reviews = apply_by_multiprocessing(\\\n",
    "    train['review'], review_to_words, workers=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T08:10:32.541762Z",
     "start_time": "2020-05-14T08:10:32.536624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    stuff go moment mj start listen music watch od...\n",
       "1    classic war world timothi hine entertain film ...\n",
       "2    film start manag nichola bell give welcom inve...\n",
       "3    must assum prais film greatest film opera ever...\n",
       "4    superbl trashi wondrous unpretenti exploit hoo...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T07:56:12.521722Z",
     "start_time": "2020-05-14T07:55:54.995816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.3 ms, sys: 118 ms, total: 215 ms\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%time clean_test_reviews = apply_by_multiprocessing(\\\n",
    "    test['review'], review_to_words, workers=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T08:21:06.189570Z",
     "start_time": "2020-05-14T08:21:06.126790Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/p1_clean_train_reviews.p', 'wb') as file:\n",
    "    pickle.dump(clean_train_reviews, file)\n",
    "    \n",
    "with open('data/p1_clean_test_reviews.p', 'wb') as file:\n",
    "    pickle.dump(clean_test_reviews, file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cf. 워드 클라우드\n",
    "\n",
    "- 단어의 빈도 수 데이터를 가지고 있을 때 이용할 수 있는 시각화 방법\n",
    "- 단순히 빈도 수를 표현하기 보다는 상관관계나 유사도 등으로 배치하는 게 더 의미 있기 때문에 큰 정보를 얻기는 어렵다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T04:19:07.614287Z",
     "start_time": "2020-05-13T04:08:39.943294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.7.0-cp36-cp36m-macosx_10_6_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 25 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow\n",
      "  Downloading Pillow-7.1.2-cp36-cp36m-macosx_10_10_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.2.1-cp36-cp36m-macosx_10_9_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 15 kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /Users/imsoyoung/opt/anaconda3/envs/nlp/lib/python3.6/site-packages (from wordcloud) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/imsoyoung/opt/anaconda3/envs/nlp/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/imsoyoung/opt/anaconda3/envs/nlp/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp36-cp36m-macosx_10_9_x86_64.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 15 kB/s eta 0:00:015\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/imsoyoung/opt/anaconda3/envs/nlp/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.14.0)\n",
      "Installing collected packages: pillow, cycler, kiwisolver, matplotlib, wordcloud\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.2.1 pillow-7.1.2 wordcloud-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T04:19:11.066512Z",
     "start_time": "2020-05-13T04:19:07.673918Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline 설정을 해주어야지만 노트북 안에 그래프가 디스플레이 된다.\n",
    "%matplotlib inline\n",
    "\n",
    "def displayWordCloud(data = None, backgroundcolor = 'white', width=800, height=600 ):\n",
    "    wordcloud = WordCloud(stopwords = STOPWORDS, \n",
    "                          background_color = backgroundcolor, \n",
    "                         width = width, height = height).generate(data)\n",
    "    plt.figure(figsize = (15 , 10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T04:45:29.355420Z",
     "start_time": "2020-05-13T04:45:29.353043Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습 데이터의 모든 단어에 대한 워드 클라우드를 그려본다.\n",
    "# %time displayWordCloud(' '.join(clean_train_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 수\n",
    "train['num_words'] = clean_train_reviews.apply(lambda x: len(str(x).split()))\n",
    "# 중복을 제거한 단어 수\n",
    "train['num_uniq_words'] = clean_train_reviews.apply(lambda x: len(set(str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터의 모든 단어에 대한 워드 클라우드를 그려본다.\n",
    "%time displayWordCloud(' '.join(clean_test_reviews))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
